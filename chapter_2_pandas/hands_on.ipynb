{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0944dfb2-0e8d-47df-8e9e-3b8ac6f744d0",
      "metadata": {},
      "source": [
        "# Data wrangling\n",
        "\n",
        "You know the basics. What are Jupyter notebooks, how do they work, and\n",
        "how do you run Python in them. It is time to start using them for data\n",
        "science (no, that simple math you did the last time doesn’t count as\n",
        "data science).\n",
        "\n",
        "You are about to enter the PyData ecosystem. It means that you will\n",
        "start learning how to work with Python from the middle. This course does\n",
        "not explicitly cover the fundamentals of programming. It is expected\n",
        "that those parts you need you’ll be able to pick as you go through the\n",
        "specialised data science stack. If you’re stuck, confused or need\n",
        "further explanation, use Google (or your favourite search engine), ask\n",
        "AI to explain the code or ask on Discord or during the class. Not\n",
        "everything will be told during the course (by design), and the internet\n",
        "is a friend of every programmer, so let’s figure out how to use it\n",
        "efficiently from the beginning.\n",
        "\n",
        "Let’s dig in!\n",
        "\n",
        "## Munging and wrangling\n",
        "\n",
        "Real-world datasets are messy. There is no way around it: datasets have\n",
        "“holes” (missing data), the amount of formats in which data can be\n",
        "stored is endless, and the best structure to share data is not always\n",
        "the optimum to analyse them, hence the need to\n",
        "[munge](http://dictionary.reference.com/browse/munge)[1] them. As has\n",
        "been correctly pointed out in many outlets, much of the time spent in\n",
        "what is called Data Science is related not only to sophisticated\n",
        "modelling and insight but has to do with much more basic and less exotic\n",
        "tasks such as obtaining data, processing, and turning them into a shape\n",
        "that makes analysis possible, and exploring it to get to know their\n",
        "basic properties.\n",
        "\n",
        "Surprisingly, very little has been published on patterns, techniques,\n",
        "and best practices for quick and efficient data cleaning, manipulation,\n",
        "and transformation because of how labour-intensive and relevant this\n",
        "aspect is. In this session, you will use a few real-world datasets and\n",
        "learn how to process them into Python so they can be transformed and\n",
        "manipulated, if necessary, and analysed. For this, you will introduce\n",
        "some of the bread and butter of data analysis and scientific computing\n",
        "in Python. These are fundamental tools that are constantly used in\n",
        "almost any task relating to data analysis.\n",
        "\n",
        "This notebook covers the basics and the content that is expected to be\n",
        "learnt by every student. You use a prepared dataset that saves us much\n",
        "of the more intricate processing that goes beyond the introductory level\n",
        "the session is aimed at. If you are interested in how it was done, there\n",
        "is a\n",
        "[notebook](https://github.com/martinfleis/sds/blob/main/data/chicago_influenza_1918/preprocessing.ipynb).\n",
        "\n",
        "This notebook discusses several patterns to clean and structure data\n",
        "properly, including tidying, subsetting, and aggregating. You finish\n",
        "with some basic visualisation. An additional extension presents more\n",
        "advanced tricks to manipulate tabular data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset\n",
        "\n",
        "You will be exploring demographic characteristics of Madrid \n",
        "\n",
        "\n",
        "The data has been aggregated to a neighbourhood level by the statistic's office of Madrid's City Hall. It contains information \n",
        "### _GREG TO UPDATE_\n",
        "\n",
        "As with many datasets that will be used during this course, the data was originally gound in the data portal on the [following link](https://datos.madrid.es/portal/site/egob/menuitem.c05c1f754a33a9fbe4b2e4b284f1a5a0/?vgnextoid=0cccaebc07c1f710VgnVCM2000001f4a900aRCRD&vgnextchannel=374512b9ace9f310VgnVCM100000171f5a0aRCRD&vgnextfmt=default)\n",
        "\n",
        "The main tool you should use for this task is the `pandas` package. As with the `math` you used [before](../chapter_1_jupyter/notebooks_and_python.ipynb), you must import it first.\n",
        "\n",
        "[1] Data munging and data wrangling are used interchangeably. Pick the\n",
        "one you like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ae259309",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7ffddbf-c5c5-42cc-a25b-742fe7f3f4a5",
      "metadata": {},
      "source": [
        "The data is stored in a CSV file. To make things easier, you can read\n",
        "data from a file posted online so, for now, you do not need to download\n",
        "any dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "32a8c692",
      "metadata": {},
      "outputs": [],
      "source": [
        "madrid_pop = pd.read_csv(\n",
        "    \"https://datos.madrid.es/egob/catalogo/300557-0-poblacion-distrito-barrio.csv\",\n",
        "    sep=\";\",\n",
        "    index_col=\"distrito\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2be8b4aa-db29-4cde-b594-37d9981285b7",
      "metadata": {},
      "source": [
        "> **Tip**\n",
        ">\n",
        "> You are using `read_csv` because the file you want to read is in CSV\n",
        "> format. However, the current data is actually not separated by _commas_ `,`\n",
        "> but with a semicolon `;`, hence the additional parameter in the code.\n",
        ">\n",
        "> Note that `pandas` allows for many more formats to be read and\n",
        "> write. A full list of formats supported may be found in [the\n",
        "> documentation](https://pandas.pydata.org/docs/user_guide/io.html).\n",
        "\n",
        "> **Alternative**\n",
        ">\n",
        "> Instead of reading the file directly off the web, it is possible to\n",
        "> download it manually, store it on your computer, and read it locally.\n",
        "> To do that, you can follow these steps:\n",
        ">\n",
        "> 1.  Download the file by clicking on [this\n",
        ">     link](https://datos.madrid.es/egob/catalogo/300557-0-poblacion-distrito-barrio.csv)\n",
        ">     and saving the file\n",
        "> 2.  Place the file in the same folder as the notebook where you intend\n",
        ">     to read it\n",
        "> 3.  Replace the code in the cell above with:\n",
        ">\n",
        "> ``` python\n",
        "> madrid_pop = pd.read_csv(\n",
        ">     \"poblacion_1_enero.csv\",\n",
        ">     sep=\";\",\n",
        ">     index_col=\"distrito\",\n",
        "> )\n",
        "> ```\n",
        "\n",
        "## Pandas 101\n",
        "\n",
        "Now, you are ready to start playing and interrogating the dataset! What\n",
        "you have at your fingertips is a table summarising, for each of the\n",
        "census tracts in Chicago more than a century ago, how many people lived\n",
        "in each by age, accompanied by some other socioeconomic data and\n",
        "influenza mortality. These tables are called `DataFrame` objects, and\n",
        "they have a lot of functionality built-in to explore and manipulate the\n",
        "data they contain. Let’s explore a few of those cool tricks!\n",
        "\n",
        "### Data Structures\n",
        "\n",
        "The first aspect worth spending a bit of time on is the structure of a\n",
        "`DataFrame`. You can print it by simply typing its name:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "870dd8a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "chicago_1918"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a284c204-aace-46a0-9d44-4a0bca30ebb4",
      "metadata": {},
      "source": [
        "Note the printing is cut to keep a nice and compact view but enough to\n",
        "see its structure. Since they represent a table of data, `DataFrame`\n",
        "objects have two dimensions: rows and columns. Each of these is\n",
        "automatically assigned a name in what you will call its *index*. When\n",
        "printing, the index of each dimension is rendered in bold, as opposed to\n",
        "the standard rendering for the content. The example above shows how the\n",
        "column index is automatically picked up from the `.csv` file’s column\n",
        "names. For rows, we have specified when reading the file you wanted the\n",
        "column `geography_code`, so that is used. If you hadn’t set any,\n",
        "`pandas` would automatically generate a sequence starting in `0` and\n",
        "going all the way to the number of rows minus one. This is the standard\n",
        "structure of a `DataFrame` object, so you will come to it over and over.\n",
        "Importantly, even when you move to spatial data, your datasets will have\n",
        "a similar structure.\n",
        "\n",
        "One final feature that is worth mentioning about these tables is that\n",
        "they can hold columns with different types of data. In this example, you\n",
        "have counts (or `int` for integer types) and ratios (or ‘float’ for\n",
        "floating point numbers - a number with decimals) for each column. But it\n",
        "is useful to keep in mind that you can combine this with columns that\n",
        "hold other types of data such as categories, text (`str`, for string),\n",
        "dates or, as you will see later in the course, geographic features.\n",
        "\n",
        "To extract a single column from this `DataFrame`, specify its name in\n",
        "the square brackets (`[]`). Note that the name, in this case, is a\n",
        "`string`. A piece of text. As such, it needs to be within single (`'`)\n",
        "or double quotes (`\"`). The resulting data structure is no longer a\n",
        "`DataFrame`, but you have a `Series` because you deal with a single\n",
        "column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7a3fd02",
      "metadata": {},
      "outputs": [],
      "source": [
        "chicago_1918[\"influenza\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0b31e0d-37ef-4245-817a-ffec71804421",
      "metadata": {},
      "source": [
        "### Inspect\n",
        "\n",
        "Inspecting what it looks like. You can check the table’s top (or bottom)\n",
        "X lines by passing X to the method `head` (`tail`). For example, for the\n",
        "top/bottom five lines:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c13eeff",
      "metadata": {},
      "outputs": [],
      "source": [
        "chicago_1918.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a00b0027",
      "metadata": {},
      "outputs": [],
      "source": [
        "chicago_1918.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "259dfd80-11b6-4087-b665-6a4b29ca8b7e",
      "metadata": {},
      "source": [
        "Or get an overview of the table:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d80a3eba",
      "metadata": {},
      "outputs": [],
      "source": [
        "chicago_1918.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdcc82e3-8d4e-40c9-91c6-44acff191990",
      "metadata": {},
      "source": [
        "### Summarise\n",
        "\n",
        "Or of the *values* of the table:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2df5cbb",
      "metadata": {},
      "outputs": [],
      "source": [
        "chicago_1918.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb27253f-195c-4df1-a40c-5cbc8b0c500a",
      "metadata": {},
      "source": [
        "Note how the output is also a `DataFrame` object, so you can do with it\n",
        "the same things you would with the original table (e.g. writing it to a\n",
        "file).\n",
        "\n",
        "In this case, the summary might be better presented if the table is\n",
        "“transposed”:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ecae769",
      "metadata": {},
      "outputs": [],
      "source": [
        "chicago_1918.describe().T"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bc9cad4-b122-4274-829b-4e473535d264",
      "metadata": {},
      "source": [
        "Equally, common descriptive statistics are also available. To obtain\n",
        "minimum values for each column, you can use `.min()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8106890",
      "metadata": {},
      "outputs": [],
      "source": [
        "chicago_1918.min()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd39ccd4-8b51-4820-a3cd-f5f88247e7db",
      "metadata": {},
      "source": [
        "Or to obtain a minimum for a single column only."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1cbab33",
      "metadata": {},
      "outputs": [],
      "source": [
        "chicago_1918[\"influenza\"].min()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "644bf76d-9dd5-4afa-b6da-11572724a530",
      "metadata": {},
      "source": [
        "Note here how you have restricted the calculation of the minimum value\n",
        "to one column only by getting the `Series` and calling `.min()` on that.\n",
        "\n",
        "Similarly, you can restrict the calculations to a single row using\n",
        "`.loc[]` indexer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b209daa",
      "metadata": {},
      "outputs": [],
      "source": [
        "chicago_1918.loc[\"G17003100492\"].max()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac4c9f62-43b3-4dca-9a0e-9100ba7085f0",
      "metadata": {},
      "source": [
        "### Create new columns\n",
        "\n",
        "You can generate new variables by applying operations to existing ones.\n",
        "For example, you can calculate the total population by area. Here are a\n",
        "couple of ways to do it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a344b3ee",
      "metadata": {},
      "outputs": [],
      "source": [
        "# This one is longer, hardcoded\n",
        "total_population = (\n",
        "    chicago_1918[\"agecat1\"]\n",
        "    + chicago_1918[\"agecat2\"]\n",
        "    + chicago_1918[\"agecat3\"]\n",
        "    + chicago_1918[\"agecat4\"]\n",
        "    + chicago_1918[\"agecat5\"]\n",
        "    + chicago_1918[\"agecat6\"]\n",
        "    + chicago_1918[\"agecat7\"]\n",
        ")\n",
        "total_population.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2da2b79b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# This one is shorted, using a range of columns and sum\n",
        "total_population = chicago_1918.loc[:, \"agecat1\":\"agecat7\"].sum(axis=1)\n",
        "total_population.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52b579a8-0ffe-4e39-a3f2-782069edf07e",
      "metadata": {},
      "source": [
        "Once you have created the variable, you can make it part of the table:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d11ac4d",
      "metadata": {},
      "outputs": [],
      "source": [
        "chicago_1918[\"total_population\"] = total_population\n",
        "chicago_1918.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b01e5508-e06b-4062-86a3-f44d02c806a3",
      "metadata": {},
      "source": [
        "You can also do other mathematical operations on columns. These are\n",
        "always automatically applied to individual values in corresponding rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39bc19ea",
      "metadata": {},
      "outputs": [],
      "source": [
        "homeowners = chicago_1918[\"total_population\"] * chicago_1918[\"ho_pct\"]\n",
        "homeowners.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53ca60c7",
      "metadata": {},
      "outputs": [],
      "source": [
        "pop_density = chicago_1918[\"total_population\"] / chicago_1918[\"gross_acres\"]\n",
        "pop_density.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf0b621e-b869-422c-91f8-e19f1ea8ca3e",
      "metadata": {},
      "source": [
        "A different spin on this is assigning new values: you can generate new\n",
        "variables with scalars[1], and modify those:\n",
        "\n",
        "[1] Scalar is a single value, like a number (`42`) or a string\n",
        "(`\"towel\"`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ceb49c0a",
      "metadata": {},
      "outputs": [],
      "source": [
        "chicago_1918[\"ones\"] = 1\n",
        "chicago_1918.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bacb249-0aca-40a7-84d3-c4da42944a4e",
      "metadata": {},
      "source": [
        "And you can modify specific values too:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c0d2228",
      "metadata": {},
      "outputs": [],
      "source": [
        "chicago_1918.loc[\"G17003100001\", \"ones\"] = 3\n",
        "chicago_1918.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08e453b4-3300-4c44-9a57-c6617ed1d807",
      "metadata": {},
      "source": [
        "### Remove columns\n",
        "\n",
        "Permanently deleting variables is also within reach of one command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b0a1cce",
      "metadata": {},
      "outputs": [],
      "source": [
        "chicago_1918 = chicago_1918.drop(columns=\"ones\")\n",
        "chicago_1918.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19a85908-eda8-417e-bd8e-0725ca4bf368",
      "metadata": {},
      "source": [
        "### Index-based queries\n",
        "\n",
        "Here, you explore how to subset parts of a `DataFrame` if you know\n",
        "exactly which bits you want. For example, if you want to extract the\n",
        "influenza mortality and total population of the first four areas in the\n",
        "table, you use `loc` with lists:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf544d13",
      "metadata": {},
      "outputs": [],
      "source": [
        "death_pop_first4 = chicago_1918.loc[\n",
        "    [\"G17003100001\", \"G17003100002\", \"G17003100003\", \"G17003100004\"],\n",
        "    [\"influenza\", \"total_population\"],\n",
        "]\n",
        "death_pop_first4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "181955e4-5301-4d16-816e-52dd8615f436",
      "metadata": {},
      "source": [
        "You can see how you can create a list with the names (index IDs) along\n",
        "each of the two dimensions of a `DataFrame` (rows and columns), and\n",
        "`loc` will return a subset of the original table only with the elements\n",
        "queried for.\n",
        "\n",
        "An alternative to list-based queries is what is called “range-based”\n",
        "queries. These work on the indices of the table, but instead of\n",
        "requiring the ID of each item you want to retrieve, they operate by\n",
        "requiring only two IDs: the first and last element in a range of items.\n",
        "Range queries are expressed with a colon (`:`). For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e25b1fb",
      "metadata": {},
      "outputs": [],
      "source": [
        "range_query = chicago_1918.loc[\n",
        "    \"G17003100010\":\"G17003100012\",\n",
        "    \"influenza\":'total_population',\n",
        "]\n",
        "range_query"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "339f33d2-d7cf-4dab-85cd-57fa6e6f0644",
      "metadata": {},
      "source": [
        "The range query picks up all the elements between the specified IDs.\n",
        "Note that for this to work, the first ID in the range needs to be placed\n",
        "before the second one in the table’s index.\n",
        "\n",
        "Once you know about list and range-based queries, you can combine them!\n",
        "For example, you can specify a range of rows and a list of columns:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "647964c8",
      "metadata": {},
      "outputs": [],
      "source": [
        "range_list_qry = chicago_1918.loc[\n",
        "    \"G17003100010\":\"G17003100012\", [\"influenza\", \"total_population\"]\n",
        "]\n",
        "\n",
        "range_list_qry"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00233a98-a499-4d66-b3ce-9dfa9f46c459",
      "metadata": {},
      "source": [
        "### Condition-based queries\n",
        "\n",
        "However, sometimes, you do not know exactly which observations you want,\n",
        "but you do know what conditions they need to satisfy (e.g. areas with\n",
        "more than 2,000 inhabitants). For these cases, `DataFrames` support\n",
        "selection based on conditions. Let us see a few examples. Suppose you\n",
        "want to select…\n",
        "\n",
        "*… areas with more than 60 cases of influenza deaths:*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6df973c7",
      "metadata": {},
      "outputs": [],
      "source": [
        "flu_over_60 = chicago_1918.loc[chicago_1918[\"influenza\"] > 60]\n",
        "flu_over_60"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d008be0c-9798-479b-9f84-749e623ba4f6",
      "metadata": {},
      "source": [
        "*… areas with less than 200 inhabitants:*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c3affa0",
      "metadata": {},
      "outputs": [],
      "source": [
        "pop_under = chicago_1918.loc[chicago_1918[\"total_population\"] < 200]\n",
        "pop_under"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37156ae4-2abb-41d8-9c32-af7fec87ef1b",
      "metadata": {},
      "source": [
        "*… areas with exactly a hundred illiterate persons:*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f173ba3",
      "metadata": {},
      "outputs": [],
      "source": [
        "illit_100 = chicago_1918.loc[chicago_1918[\"illit\"] == 100]\n",
        "illit_100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cc14cd0-b001-43d2-a229-2fdf87dbf262",
      "metadata": {},
      "source": [
        "> **Unlimited power**\n",
        ">\n",
        "> These queries can grow in sophistication with almost no limits. For\n",
        "> example, here is a case where you want to find out the areas where the\n",
        "> oldest age group is more than half the population:\n",
        ">\n",
        "> ``` python\n",
        "> chicago_1918.loc[\n",
        ">     (chicago_1918[\"agecat7\"] * 100 / chicago_1918[\"total_population\"]) > 50\n",
        "> ]\n",
        "> ```\n",
        ">\n",
        "> <div>\n",
        "> <style scoped>\n",
        ">     .dataframe tbody tr th:only-of-type {\n",
        ">         vertical-align: middle;\n",
        ">     }\n",
        ">\n",
        ">     .dataframe tbody tr th {\n",
        ">         vertical-align: top;\n",
        ">     }\n",
        ">\n",
        ">     .dataframe thead th {\n",
        ">         text-align: right;\n",
        ">     }\n",
        "> </style>\n",
        ">\n",
        "> |                | gross_acres | illit | unemployed_pct | ho_pct   | agecat1 | agecat2 | agecat3 | agecat4 | agecat5 | agecat6 | agecat7 | influenza | total_population |\n",
        "> |----------------|-------------|-------|----------------|----------|---------|---------|---------|---------|---------|---------|---------|-----------|------------------|\n",
        "> | geography_code |             |       |                |          |         |         |         |         |         |         |         |           |                  |\n",
        "> | G17003100227   | 146.3       | 22    | 0.0657         | 0.000853 | 2       | 16      | 9       | 22      | 27      | 480     | 614     | 3         | 1170             |\n",
        ">\n",
        "> </div>\n",
        "\n",
        "All the condition-based queries above are expressed using the `loc`\n",
        "operator. This is a powerful way, and since it shares syntax with\n",
        "index-based queries, it is also easier to remember. However, sometimes\n",
        "querying using `loc` involves a lot of quotation marks, parenthesis,\n",
        "etc. A more streamlined approach for condition-based queries of rows is\n",
        "provided by the `query` engine. Using this approach, you express\n",
        "everything in our query on a single string, or piece of text, and that\n",
        "is evaluated in the table at once. For example, you can run the same\n",
        "operation as in the first query above with the following syntax:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b45d6745",
      "metadata": {},
      "outputs": [],
      "source": [
        "flu_over_60_query = chicago_1918.query(\"influenza > 60\")\n",
        "flu_over_60_query"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9ec4bb9-8201-49df-bca3-e242aa399646",
      "metadata": {},
      "source": [
        "If you want to combine operations, this is also possible:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3423abc8",
      "metadata": {},
      "outputs": [],
      "source": [
        "flu_query = chicago_1918.query(\"(influenza > 60) & (total_population < 10000)\")\n",
        "flu_query"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b52669c5-31eb-49a3-8a6c-63dd7c1c1cd8",
      "metadata": {},
      "source": [
        "Note that, in these cases, using query results in code that is much more\n",
        "streamlined and easier to read. However, `query` is not perfect and,\n",
        "particularly for more sophisticated queries, it does not afford the same\n",
        "degree of flexibility. For example, the last `query` we had using loc\n",
        "would not be possible using `query`.\n",
        "\n",
        "> **Tip**\n",
        ">\n",
        "> If you are interested, more detail about `query` is available in the\n",
        "> [pandas\n",
        "> documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#the-query-method).\n",
        "\n",
        "### Combining queries\n",
        "\n",
        "Now, all of these queries can be combined with each other for further\n",
        "flexibility. For example, imagine you want areas with more than 60 cases\n",
        "of influenza from areas with less than 10,000 inhabitants:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a7ffaca",
      "metadata": {},
      "outputs": [],
      "source": [
        "flu_loc = chicago_1918.loc[\n",
        "    (chicago_1918[\"influenza\"] > 60)\n",
        "    & (chicago_1918[\"total_population\"] < 10000)\n",
        "]\n",
        "flu_loc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97bd797b-3cd6-4921-a1ec-e22ecd25f44f",
      "metadata": {},
      "source": [
        "> **How do the `loc` queries work?**\n",
        ">\n",
        "> Let’s unpack how these queries work. Each part of the query above\n",
        "> creates a single `Series` with boolean (`True` or `False`) values,\n",
        "> encoding whether the row fulfils the condition or not.\n",
        ">\n",
        "> ``` python\n",
        "> chicago_1918[\"influenza\"] > 60\n",
        "> ```\n",
        ">\n",
        ">     geography_code\n",
        ">     G17003100001    False\n",
        ">     G17003100002    False\n",
        ">     G17003100003    False\n",
        ">     G17003100004    False\n",
        ">     G17003100005    False\n",
        ">                     ...  \n",
        ">     G17003100492    False\n",
        ">     G17003100493    False\n",
        ">     G17003100494     True\n",
        ">     G17003100495    False\n",
        ">     G17003100496    False\n",
        ">     Name: influenza, Length: 496, dtype: bool\n",
        ">\n",
        "> ``` python\n",
        "> chicago_1918[\"total_population\"] < 10000\n",
        "> ```\n",
        ">\n",
        ">     geography_code\n",
        ">     G17003100001     True\n",
        ">     G17003100002     True\n",
        ">     G17003100003     True\n",
        ">     G17003100004     True\n",
        ">     G17003100005     True\n",
        ">                     ...  \n",
        ">     G17003100492     True\n",
        ">     G17003100493    False\n",
        ">     G17003100494    False\n",
        ">     G17003100495     True\n",
        ">     G17003100496     True\n",
        ">     Name: total_population, Length: 496, dtype: bool\n",
        ">\n",
        "> You then combine two of these Series with `&`, asking for a new\n",
        "> `Series` where values in both the first and the second `Series` are\n",
        "> `True`.\n",
        ">\n",
        "> ``` python\n",
        "> (chicago_1918[\"influenza\"] > 60) & (chicago_1918[\"total_population\"] < 10000)\n",
        "> ```\n",
        ">\n",
        ">     geography_code\n",
        ">     G17003100001    False\n",
        ">     G17003100002    False\n",
        ">     G17003100003    False\n",
        ">     G17003100004    False\n",
        ">     G17003100005    False\n",
        ">                     ...  \n",
        ">     G17003100492    False\n",
        ">     G17003100493    False\n",
        ">     G17003100494    False\n",
        ">     G17003100495    False\n",
        ">     G17003100496    False\n",
        ">     Length: 496, dtype: bool\n",
        ">\n",
        "> Such a `Series` is then essentially used as a mask, and `loc` returns\n",
        "> only those columns that contain `True` in that mask.\n",
        "\n",
        "### Sorting\n",
        "\n",
        "Among the many operations `DataFrame` objects support, one of the most\n",
        "useful ones is to sort a table based on a given column. For example,\n",
        "imagine you want to sort the table by the influenza cases:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "855ffda5",
      "metadata": {},
      "outputs": [],
      "source": [
        "chicago_sorted = chicago_1918.sort_values('influenza', ascending=False)\n",
        "chicago_sorted\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84c967c5-bf25-406d-b33a-c136e887930d",
      "metadata": {},
      "source": [
        "Given the areas of each census tract differ, it may be better to sort by\n",
        "the mortality rate rather than raw counts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bd3c0de",
      "metadata": {},
      "outputs": [],
      "source": [
        "chicago_1918[\"flu_rate\"] = (\n",
        "    chicago_1918[\"influenza\"] / chicago_1918[\"total_population\"]\n",
        ")\n",
        "chicago_sorted_rel = chicago_1918.sort_values('flu_rate', ascending=False)\n",
        "chicago_sorted_rel\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18321e96-66cf-4e7b-8ab4-b2985f46843b",
      "metadata": {},
      "source": [
        "If you inspect the help of `chicago_1918.sort_values`, you will find\n",
        "that you can pass more than one column to sort the table by. This allows\n",
        "you to do so-called hierarchical sorting: sort first based on one\n",
        "column, if equal, then based on another column, etc.\n",
        "\n",
        "## Visual Exploration\n",
        "\n",
        "The next step to continue exploring a dataset is to get a feel for what\n",
        "it looks like, visually. You have already learnt how to unconver and\n",
        "inspect specific parts of the data, to check for particular cases you\n",
        "might be interested in. Now, you will see how to plot the data to get a\n",
        "sense of the overall distribution of values. For that, you can use the\n",
        "plotting capabilities of `pandas`.\n",
        "\n",
        "### Histograms\n",
        "\n",
        "One of the most common graphical devices to display the distribution of\n",
        "values in a variable is a histogram. Values are assigned into groups of\n",
        "equal intervals, and the groups are plotted as bars rising as high as\n",
        "the number of values into the group.\n",
        "\n",
        "A histogram is easily created with the following command. In this case,\n",
        "let us have a look at the shape of the overall influenza rates:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cc034b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "_ = chicago_1918[\"influenza\"].plot.hist()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef6d3bde-0b9d-47ff-8f61-fbddac620331",
      "metadata": {},
      "source": [
        "> **Assigning to `_`**\n",
        ">\n",
        "> `pandas` returns an object with the drawing from its plotting methods.\n",
        "> Since you are in Jupyter environment, and you don’t need to work\n",
        "> further with that object; you can assign it to `_`, a convention for\n",
        "> an unused variable.\n",
        "\n",
        "However, the default `pandas` plots can be a bit dull. A better option\n",
        "is to use another package, called\n",
        "[`seaborn`](https://seaborn.pydata.org)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eea1013e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28bdde0e-5725-4e9c-bb3c-5e00a7c5962a",
      "metadata": {},
      "source": [
        "> **Why `sns`?**\n",
        ">\n",
        "> `seaborn` is, by convention, imported as `sns`. That came as a joke\n",
        "> after [Samuel Normal\n",
        "> Seaborn](https://en.wikipedia.org/wiki/Sam_Seaborn), a fictional\n",
        "> character The West Wing show.\n",
        "\n",
        "The same plot using `seaborn` has a more pleasant default style and more\n",
        "customisability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39d67964",
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.displot(chicago_1918[\"influenza\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66916c32-4f8c-44b3-a938-8421b8cb58e7",
      "metadata": {},
      "source": [
        "Note you are using `sns` instead of `pd`, as the function belongs to\n",
        "`seaborn` instead of `pandas`.\n",
        "\n",
        "You can quickly see most of the areas have seen somewhere between 0 and\n",
        "60 cases, approx. However, there are a few areas that have more, up to\n",
        "more than 80 cases.\n",
        "\n",
        "### Kernel Density Plots\n",
        "\n",
        "Histograms are useful, but they are artificial in the sense that a\n",
        "continuous variable is made discrete by turning the values into discrete\n",
        "groups. An alternative is kernel density estimation (KDE), which\n",
        "produces an empirical density function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd3671c3",
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.displot(chicago_1918[\"influenza\"], kind=\"kde\", fill=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4f3e164-6927-4f87-8e04-8157ba87e1a9",
      "metadata": {},
      "source": [
        "### Line and bar plots\n",
        "\n",
        "Another very common way of visually displaying a variable is with a line\n",
        "or a bar chart. For example, if you want to generate a line plot of the\n",
        "(sorted) total cases by area:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dbc0d76",
      "metadata": {},
      "outputs": [],
      "source": [
        "_ = chicago_1918[\"influenza\"].sort_values(ascending=False).plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2090b601-348b-42c6-875a-3a78728c6dce",
      "metadata": {},
      "source": [
        "For a bar plot all you need to do is to change from `plot` to\n",
        "`plot.bar`. Since there are many census tracts, let us plot only the ten\n",
        "largest ones (which you can retrieve with `head`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "934ec86f",
      "metadata": {},
      "outputs": [],
      "source": [
        "_ = chicago_1918[\"influenza\"].sort_values(ascending=False).head(10).plot.bar()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc907916-04a3-4012-9507-5174d221c2a9",
      "metadata": {},
      "source": [
        "You can turn the plot around by displaying the bars horizontally (see\n",
        "how it’s just changing `bar` for `barh`). Let’s display now the top 50\n",
        "areas and, to make it more readable, let us expand the plot’s height:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cca20461",
      "metadata": {},
      "outputs": [],
      "source": [
        "_ = (\n",
        "    chicago_1918[\"total_population\"]\n",
        "    .sort_values()\n",
        "    .head(50)\n",
        "    .plot.barh(figsize=(6, 20))\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10bd3392-3e57-475e-8bc2-311d0c20c126",
      "metadata": {},
      "source": [
        "> **One line or multiple lines?**\n",
        ">\n",
        "> You may have noticed that in some cases, the code is on a single line,\n",
        "> but longer code is split into multiple lines. Python requires you to\n",
        "> follow the [indentation rules](https://peps.python.org/pep-0008/), but\n",
        "> apart from that, there are not a lot of other limits.\n",
        "\n",
        "## Tidy data\n",
        "\n",
        "> **Caution**\n",
        ">\n",
        "> This section is a bit more advanced and hence considered optional.\n",
        "> Feel free to skip it, move to the next, and return later when you feel\n",
        "> more confident.\n",
        "\n",
        "Once you can read your data in, explore specific cases, and have a first\n",
        "visual approach to the entire set, the next step can be preparing it for\n",
        "more sophisticated analysis. Maybe you are thinking of modeling it\n",
        "through regression, or on creating subgroups in the dataset with\n",
        "particular characteristics, or maybe you simply need to present summary\n",
        "measures that relate to a slightly different arrangement of the data\n",
        "than you have been presented with.\n",
        "\n",
        "For all these cases, you first need what statistician, and general R\n",
        "wizard, Hadley Wickham calls *“tidy data”*. The general idea to “tidy”\n",
        "your data is to convert them from whatever structure they were handed in\n",
        "to you into one that allows convenient and standardized manipulation,\n",
        "and that supports directly inputting the data into what he calls\n",
        "“*tidy*” analysis tools. But, at a more practical level, what is exactly\n",
        "*“tidy data”*? In Wickham’s own words:\n",
        "\n",
        "> *Tidy data is a standard way of mapping the meaning of a dataset to\n",
        "> its structure. A dataset is messy or tidy depending on how rows,\n",
        "> columns and tables are matched up with observations, variables and\n",
        "> types.*\n",
        "\n",
        "He then goes on to list the three fundamental characteristics of *“tidy\n",
        "data”*:\n",
        "\n",
        "1.  Each variable forms a column.\n",
        "2.  Each observation forms a row.\n",
        "3.  Each type of observational unit forms a table.\n",
        "\n",
        "If you are further interested in the concept of *“tidy data”*, I\n",
        "recommend you check out the [original\n",
        "paper](http://www.jstatsoft.org/v59/i10/) (open access) and the [public\n",
        "repository](https://github.com/hadley/tidy-data) associated with it.\n",
        "\n",
        "Let us bring in the concept of “*tidy data*” to our own Chicago dataset.\n",
        "First, remember its structure:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "362b2d92",
      "metadata": {},
      "outputs": [],
      "source": [
        "chicago_1918.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f5dd99e-0a9e-41f3-91e3-ee5d5c76cdb3",
      "metadata": {},
      "source": [
        "Thinking through *tidy* lenses, this is not a tidy dataset. It is not so\n",
        "for each of the three conditions:\n",
        "\n",
        "-   Starting by the last one (*each type of observational unit forms a\n",
        "    table*), this dataset actually contains not one but many\n",
        "    observational units: the different areas of Chicago, captured by\n",
        "    `geography_code`; *and* different observatoins for each area. To\n",
        "    *tidy* up this aspect, you can create separate tables. You will\n",
        "    probably want population groups divided by age as one tidy table and\n",
        "    flu rates as another. Start by extracting relevant columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55387e22",
      "metadata": {},
      "outputs": [],
      "source": [
        "influenza_rates = chicago_1918[[\"influenza\"]]\n",
        "influenza_rates.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "311f2485",
      "metadata": {},
      "outputs": [],
      "source": [
        "population = chicago_1918.loc[:, \"agecat1\":\"agecat7\"]\n",
        "population.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d6b0930-1b36-40e3-9322-2f909b602886",
      "metadata": {},
      "source": [
        "At this point, the table `influenza_rates` is tidy: every row is an\n",
        "observation, every table is a variable, and there is only one\n",
        "observational unit in the table.\n",
        "\n",
        "The other table (`population`), however, is not entirely tidied up yet:\n",
        "there is only one observational unit in the table, true; but every row\n",
        "is not an observation, and there are variable values as the names of\n",
        "columns (in other words, every column is not a variable). To obtain a\n",
        "fully tidy version of the table, you need to re-arrange it in a way that\n",
        "every row is an age category in an area, and there are three variables:\n",
        "`geography_code`, age category, and population count (or frequency).\n",
        "\n",
        "Because this is actually a fairly common pattern, there is a direct way\n",
        "to solve it in `pandas`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bfdd768",
      "metadata": {},
      "outputs": [],
      "source": [
        "tidy_population = population.stack()\n",
        "tidy_population.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "126eb9da-ae24-4bbd-8c2d-94f48e0f5d64",
      "metadata": {},
      "source": [
        "The method `stack`, well, “stacks” the different columns into rows. This\n",
        "fixes our “tidiness” problems but the type of object that is returning\n",
        "is not a `DataFrame`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6ebe1b3",
      "metadata": {},
      "outputs": [],
      "source": [
        "type(tidy_population)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d55b265e-6740-421a-b64a-3ffb8142d2a6",
      "metadata": {},
      "source": [
        "It is a `Series`, which really is like a `DataFrame`, but with only one\n",
        "column. The additional information (`geography_code` and age category)\n",
        "are stored in what is called an multi-index. You will skip these for\n",
        "now, so you would really just want to get a `DataFrame` as you know it\n",
        "out of the `Series`. This is also one line of code away:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3684808a",
      "metadata": {},
      "outputs": [],
      "source": [
        "tidy_population_df = tidy_population.reset_index()\n",
        "tidy_population_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac52af0d-31b0-4b06-9974-334e7ea472b5",
      "metadata": {},
      "source": [
        "To which you can apply to renaming to make it look better:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aef29a3c",
      "metadata": {},
      "outputs": [],
      "source": [
        "tidy_population_df = tidy_population_df.rename(\n",
        "    columns={\"level_1\": \"age_category\", 0: \"count\"}\n",
        ")\n",
        "tidy_population_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "513bee4a-9b5e-41d9-bcaf-b55f6fa4fa1d",
      "metadata": {},
      "source": [
        "Now our table is fully tidied up!\n",
        "\n",
        "## Grouping, transforming, aggregating\n",
        "\n",
        "One of the advantage of tidy datasets is they allow to perform advanced\n",
        "transformations in a more direct way. One of the most common ones is\n",
        "what is called “group-by” operations. Originated in the world of\n",
        "databases, these operations allow you to group observations in a table\n",
        "by one of its labels, index, or category, and apply operations on the\n",
        "data group by group.\n",
        "\n",
        "For example, given our tidy table with age categories, you might want to\n",
        "compute the total sum of the population by each category. This task can\n",
        "be split into two different ones:\n",
        "\n",
        "-   Group the table in each of the different subgroups.\n",
        "-   Compute the sum of `count` for each of them.\n",
        "\n",
        "To do this in `pandas`, meet one of its workhorses, and also one of the\n",
        "reasons why the library has become so popular: the `groupby` operator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8aed838c",
      "metadata": {},
      "outputs": [],
      "source": [
        "pop_grouped = tidy_population_df.groupby(\"age_category\")\n",
        "pop_grouped"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b47b72ad-4e5b-4ea8-8ba1-371ca4027869",
      "metadata": {},
      "source": [
        "The object `pop_grouped` still hasn’t computed anything. It is only a\n",
        "convenient way of specifying the grouping. But this allows us then to\n",
        "perform a multitude of operations on it. For our example, the sum is\n",
        "calculated as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ce0826b",
      "metadata": {},
      "outputs": [],
      "source": [
        "pop_grouped.sum(numeric_only=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cb86d54-8ad5-4837-99f6-4e50ce76c297",
      "metadata": {},
      "source": [
        "Similarly, you can also obtain a summary of each group:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c79783a2",
      "metadata": {},
      "outputs": [],
      "source": [
        "pop_grouped.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82e68b7b-8c33-4ab1-931a-9d735787a81c",
      "metadata": {},
      "source": [
        "You will not get into it today as it goes beyond the basics this chapter\n",
        "wants to cover, but keep in mind that `groupby` allows you to not only\n",
        "call generic functions (like `sum` or `describe`), but also your own\n",
        "functions. This opens the door for virtually any kind of transformation\n",
        "and aggregation possible.\n",
        "\n",
        "> **Additional reading**\n",
        ">\n",
        "> -   A good introduction to data manipulation in Python is Wes\n",
        ">     McKinney’s “[Python for Data\n",
        ">     Analysis](https://wesmckinney.com/book/pandas-basics)”\n",
        ">     \\[@mckinney2012python\\].\n",
        "> -   To explore further some of the visualization capabilities in at\n",
        ">     your fingertips, the Python library `seaborn` is an excellent\n",
        ">     choice. Its online\n",
        ">     [tutorial](https://seaborn.pydata.org/tutorial.html) is a\n",
        ">     fantastic place to start.\n",
        "> -   A good extension is Hadley Wickham’s “Tidy data” paper\n",
        ">     \\[@wickham2014tidy\\], which presents a very popular way of\n",
        ">     organising tabular data for efficient manipulation.\n",
        "\n",
        "## Acknowledgements\n",
        "\n",
        "This section is derived from *A Course on Geographic Data Science* by\n",
        "@darribas_gds_course, licensed under CC-BY-SA 4.0. The text was slightly\n",
        "adapted, mostly to accommodate a different dataset used."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "nfiua",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
